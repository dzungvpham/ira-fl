{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from attack import (\n",
    "    reconstruct_interactions,\n",
    "    interaction_mia_fedrec,\n",
    ")\n",
    "from dataset import (\n",
    "    LearningToRankDataset,\n",
    "    MovieLens,\n",
    ")\n",
    "from more_itertools import grouper\n",
    "from ranker import (\n",
    "    LinearPDGDRanker,\n",
    "    Neural1LayerPDGDRanker,\n",
    "    Neural2LayerPDGDRanker,\n",
    "    CollaborativeFilteringRecommender,\n",
    "    NeuralCollaborativeFilteringRecommender,\n",
    ")\n",
    "from scipy.stats import ks_2samp\n",
    "from tqdm.notebook import tqdm\n",
    "from utils import (\n",
    "    CascadeClickModel,\n",
    "    Metrics,\n",
    "    apply_gaussian_mechanism,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ../dataset/MQ2008/Fold1/test.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2874it [00:00, 43676.74it/s]\n"
     ]
    }
   ],
   "source": [
    "def set_seed():\n",
    "    torch.manual_seed(2023)\n",
    "    random.seed(2023)\n",
    "    np.random.seed(2023)\n",
    "\n",
    "data = LearningToRankDataset(\"../dataset/MQ2008/Fold1/test.txt\")\n",
    "num_features = data.get_num_features()\n",
    "\n",
    "models = {\n",
    "    \"linear_pdgd\": LinearPDGDRanker(num_features),\n",
    "    # \"neural_4_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=4),\n",
    "    # \"neural_8_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=8),\n",
    "    # \"neural_16_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=16),\n",
    "    # \"neural_4_2_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=4, hidden_size2=2\n",
    "    # ),\n",
    "    # \"neural_8_4_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=8, hidden_size2=4\n",
    "    # ),\n",
    "    # \"neural_16_8_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=16, hidden_size2=4\n",
    "    # ),\n",
    "}\n",
    "\n",
    "click_models = {\n",
    "    # \"perfect\": CascadeClickModel(prob_click=[0.0, 0.5, 1.0], prob_stop=[0.0, 0.0, 0.0]),\n",
    "    \"navigational\": CascadeClickModel(\n",
    "        prob_click=[0.05, 0.5, 0.95], prob_stop=[0.2, 0.5, 0.9]\n",
    "    ),\n",
    "    \"informational\": CascadeClickModel(\n",
    "        prob_click=[0.4, 0.7, 0.9], prob_stop=[0.1, 0.3, 0.5]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [05:11<00:00, 31.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# Simulation for LTR\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_sim_round = 10\n",
    "num_features = 10\n",
    "num_data = 100\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "models = {\n",
    "    \"linear_pdgd\": LinearPDGDRanker(num_features),\n",
    "    # \"neural_1_pdgd\": Neural1LayerPDGDRanker(num_features, hidden_size=5),\n",
    "    # \"neural_2_pdgd\": Neural2LayerPDGDRanker(\n",
    "    #     num_features, hidden_size=4, hidden_size2=2\n",
    "    # ),\n",
    "}\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    features = torch.rand(num_data, num_features) * 2 - 1\n",
    "    interactions = torch.randint(0, 2, (num_data,))\n",
    "    while interactions.sum() == 0:\n",
    "        interactions = torch.randint(0, 2, (num_data,))\n",
    "    \n",
    "    ranking = list(range(num_data))\n",
    "    random.shuffle(ranking)\n",
    "    ranking = torch.LongTensor(ranking)\n",
    "\n",
    "    for model_name, model in models.items():\n",
    "        params = model.gen_params()\n",
    "        log_pos_bias_weight = model.calc_log_pos_bias_weight(\n",
    "            ranking, model.forward_multiple(params, features), num_data\n",
    "        )\n",
    "        \n",
    "        target = model.grad(\n",
    "            params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "            log_pos_bias_weight=log_pos_bias_weight,\n",
    "        )\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: model.grad(\n",
    "                params, features, ranking, I, log_pos_bias_weight=log_pos_bias_weight\n",
    "            ),\n",
    "            target,\n",
    "            num_data,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "        metrics.update(model_name, interactions, preds, preds_raw=preds_raw)\n",
    "\n",
    "    # Data manipulation\n",
    "    if num_data > num_features:\n",
    "        num_new_features = num_data - num_features\n",
    "        new_features = torch.rand(num_data, num_new_features)\n",
    "        features = torch.cat([features, new_features], dim=1)\n",
    "\n",
    "        model = LinearPDGDRanker(num_features + num_new_features)\n",
    "        params = model.gen_params()\n",
    "        log_pos_bias_weight = model.calc_log_pos_bias_weight(\n",
    "            ranking, model.forward_multiple(params, features), num_data\n",
    "        )\n",
    "        \n",
    "        target = model.grad(\n",
    "            params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "            log_pos_bias_weight=log_pos_bias_weight,\n",
    "        )\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: model.grad(\n",
    "                params, features, ranking, I, log_pos_bias_weight=log_pos_bias_weight\n",
    "            ),\n",
    "            target,\n",
    "            num_data,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "        metrics.update(model_name + \"_DM\", interactions, preds, preds_raw=preds_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              name  accuracy        f1  precision    recall       auc    auc-pr extra_data\n",
      "0      linear_pdgd    0.5425  0.548148   0.587302  0.513889  0.558399  0.607230         {}\n",
      "1   linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "2      linear_pdgd    0.4700  0.459184   0.505618  0.420561  0.500879  0.536752         {}\n",
      "3   linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "4      linear_pdgd    0.5250  0.520202   0.512438  0.528205  0.517724  0.485470         {}\n",
      "5   linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "6      linear_pdgd    0.4950  0.459893   0.457447  0.462366  0.504648  0.476432         {}\n",
      "7   linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "8      linear_pdgd    0.5200  0.505155   0.505155  0.505155  0.500651  0.472847         {}\n",
      "9   linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "10     linear_pdgd    0.5025  0.525060   0.555556  0.497738  0.512551  0.572833         {}\n",
      "11  linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "12     linear_pdgd    0.4950  0.516746   0.516746  0.516746  0.477492  0.502333         {}\n",
      "13  linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "14     linear_pdgd    0.5425  0.552567   0.545894  0.559406  0.544054  0.515852         {}\n",
      "15  linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "16     linear_pdgd    0.5200  0.520000   0.500000  0.541667  0.536959  0.517214         {}\n",
      "17  linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n",
      "18     linear_pdgd    0.4525  0.456576   0.438095  0.476684  0.437511  0.443380         {}\n",
      "19  linear_pdgd_DM    1.0000  1.000000   1.000000  1.000000  1.000000  1.000000         {}\n"
     ]
    }
   ],
   "source": [
    "print(metrics.get_dataframe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [01:07<00:00,  6.77s/it]\n"
     ]
    }
   ],
   "source": [
    "# Simulation for collaborative filtering\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_sim_round = 10\n",
    "num_features = 64\n",
    "num_data = 1000\n",
    "atk_lr = 1e-01\n",
    "max_iter = 100000\n",
    "num_atk = 10\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    # features = torch.rand(num_data, num_features) * 2 - 1\n",
    "    # user_embedding = torch.rand(num_features) * 2 - 1\n",
    "    # user_embedding2 = torch.rand(num_features) * 2 - 1\n",
    "    features = torch.normal(0, 1, (num_data, num_features))\n",
    "    user_embedding = torch.normal(0, 1, (num_features,))\n",
    "    user_embedding2 = torch.normal(0, 1, (num_features,))\n",
    "\n",
    "    interactions = torch.randint(0, 2, (num_data,))\n",
    "    while interactions.sum() == 0:\n",
    "        interactions = torch.randint(0, 2, (num_data,))\n",
    "\n",
    "    preds_raw = torch.rand((num_data),)\n",
    "    metrics.update(\"Random\", interactions, preds_raw.sigmoid().round().long(), preds_raw=preds_raw)\n",
    "\n",
    "    ncf_rec = NeuralCollaborativeFilteringRecommender(num_features, [128, 64, 32])\n",
    "\n",
    "    target = ncf_rec.item_grad(user_embedding, features, interactions.float())\n",
    "    scale = max(1.0 / target.mean().abs(), 1.0)\n",
    "    target = scale * target\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: scale * ncf_rec.item_grad(user_embedding2, features, I),\n",
    "        target,\n",
    "        num_data,\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "    metrics.update(\n",
    "        \"FedNCF_simple\",\n",
    "        interactions,\n",
    "        preds,\n",
    "        preds_raw=preds_raw,\n",
    "    )\n",
    "\n",
    "    target = ncf_rec.item_grad(user_embedding, features, interactions.float())\n",
    "    scale = max(1.0 / target.mean().abs(), 1.0)\n",
    "    target = scale * target\n",
    "\n",
    "    preds_raw, user_embedding_est, _ = reconstruct_interactions(\n",
    "        lambda I, U: scale * ncf_rec.item_grad(U, features, I),\n",
    "        target,\n",
    "        num_data,\n",
    "        private_params_size=num_features,\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "    \n",
    "    embedding_err = F.mse_loss(user_embedding_est, user_embedding).item()\n",
    "\n",
    "    metrics.update(\n",
    "        \"FedNCF_private\",\n",
    "        interactions,\n",
    "        preds,\n",
    "        preds_raw=preds_raw,\n",
    "        extra_data={\"embedding_err\": embedding_err},\n",
    "    )\n",
    "\n",
    "    item_grad = ncf_rec.item_grad(user_embedding, features, interactions.float()).flatten()\n",
    "    scale = max(1.0 / item_grad.mean().abs(), 1.0)\n",
    "\n",
    "    target = torch.cat(\n",
    "        [\n",
    "            scale * item_grad,\n",
    "            ncf_rec.feature_grad(user_embedding, features, interactions.float()),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    preds_raw, user_embedding_est, _ = reconstruct_interactions(\n",
    "        lambda I, U: torch.cat(\n",
    "            [\n",
    "                scale * ncf_rec.item_grad(U, features, I).flatten(),\n",
    "                ncf_rec.feature_grad(U, features, I, retain_graph=True),\n",
    "            ]\n",
    "        ),\n",
    "        target,\n",
    "        num_data,\n",
    "        private_params_size=num_features,\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "    embedding_err = F.mse_loss(user_embedding_est, user_embedding).item()\n",
    "\n",
    "    metrics.update(\n",
    "        \"FedNCF_private2\",\n",
    "        interactions,\n",
    "        preds,\n",
    "        preds_raw=preds_raw,\n",
    "        extra_data={\"embedding_err\": embedding_err},\n",
    "    )\n",
    "\n",
    "    target = ncf_rec.item_grad(user_embedding, features, interactions.float())\n",
    "\n",
    "    preds = interaction_mia_fedrec(\n",
    "        lambda I: ncf_rec.item_grad(user_embedding2, features, I.float()),\n",
    "        target,\n",
    "        num_data,\n",
    "        select_ratio=interactions.float().mean(),\n",
    "    )\n",
    "\n",
    "    metrics.update(\n",
    "        \"FedNCF_IMIA\",\n",
    "        interactions,\n",
    "        preds,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               name  accuracy        f1  precision    recall       auc    auc-pr                             extra_data\n",
      "0            Random     0.486  0.654105   0.486000  1.000000  0.514337  0.491345                                     {}\n",
      "1     FedNCF_simple     0.968  0.967871   0.945098  0.991770  0.996982  0.996428                                     {}\n",
      "2    FedNCF_private     1.000  1.000000   1.000000  1.000000  1.000000  1.000000  {\"embedding_err\": 0.9334539175033569}\n",
      "3   FedNCF_private2     0.991  0.990769   0.987730  0.993827  0.999868  0.999861  {\"embedding_err\": 1.2190757989883423}\n",
      "4       FedNCF_IMIA     0.516  0.502058   0.502058  0.502058       NaN       NaN                                     {}\n",
      "5            Random     0.507  0.672860   0.507000  1.000000  0.521126  0.518385                                     {}\n",
      "6     FedNCF_simple     0.971  0.970971   0.985772  0.956607  0.997447  0.997581                                     {}\n",
      "7    FedNCF_private     0.994  0.994071   0.996040  0.992110  0.999880  0.999887  {\"embedding_err\": 1.5219244956970215}\n",
      "8   FedNCF_private2     0.996  0.996040   1.000000  0.992110  0.999980  0.999981  {\"embedding_err\": 1.5878374576568604}\n",
      "9       FedNCF_IMIA     0.540  0.546351   0.546351  0.546351       NaN       NaN                                     {}\n",
      "10           Random     0.506  0.671979   0.506000  1.000000  0.498860  0.500161                                     {}\n",
      "11    FedNCF_simple     0.998  0.998020   1.000000  0.996047  0.999984  0.999984                                     {}\n",
      "12   FedNCF_private     1.000  1.000000   1.000000  1.000000  1.000000  1.000000  {\"embedding_err\": 1.2134686708450317}\n",
      "13  FedNCF_private2     0.999  0.999011   1.000000  0.998024  1.000000  1.000000  {\"embedding_err\": 1.0003407001495361}\n",
      "14      FedNCF_IMIA     0.541  0.545994   0.546535  0.545455       NaN       NaN                                     {}\n",
      "15           Random     0.496  0.663102   0.496000  1.000000  0.509597  0.503647                                     {}\n",
      "16    FedNCF_simple     0.965  0.964753   0.963783  0.965726  0.992980  0.992722                                     {}\n",
      "17   FedNCF_private     0.998  0.997984   0.997984  0.997984  0.999976  0.999976  {\"embedding_err\": 1.2019602060317993}\n",
      "18  FedNCF_private2     0.984  0.983838   0.985830  0.981855  0.999112  0.999119  {\"embedding_err\": 1.0231949090957642}\n",
      "19      FedNCF_IMIA     0.556  0.552419   0.552419  0.552419       NaN       NaN                                     {}\n",
      "20           Random     0.489  0.656817   0.489000  1.000000  0.494771  0.476816                                     {}\n",
      "21    FedNCF_simple     0.981  0.980943   0.962598  1.000000  0.999584  0.999548                                     {}\n",
      "22   FedNCF_private     0.994  0.993902   0.987879  1.000000  0.999988  0.999987   {\"embedding_err\": 1.245525598526001}\n",
      "23  FedNCF_private2     0.997  0.996942   0.993902  1.000000  1.000000  1.000000  {\"embedding_err\": 1.2364755868911743}\n",
      "24      FedNCF_IMIA     0.554  0.543967   0.543967  0.543967       NaN       NaN                                     {}\n",
      "25           Random     0.516  0.680739   0.516000  1.000000  0.517514  0.517563                                     {}\n",
      "26    FedNCF_simple     1.000  1.000000   1.000000  1.000000  1.000000  1.000000                                     {}\n",
      "27   FedNCF_private     1.000  1.000000   1.000000  1.000000  1.000000  1.000000  {\"embedding_err\": 1.2818337678909302}\n",
      "28  FedNCF_private2     1.000  1.000000   1.000000  1.000000  1.000000  1.000000  {\"embedding_err\": 1.3230702877044678}\n",
      "29      FedNCF_IMIA     0.530  0.544574   0.544574  0.544574       NaN       NaN                                     {}\n",
      "30           Random     0.500  0.666667   0.500000  1.000000  0.513712  0.519322                                     {}\n",
      "31    FedNCF_simple     0.903  0.904995   0.886756  0.924000  0.970144  0.971358                                     {}\n",
      "32   FedNCF_private     0.962  0.962227   0.956522  0.968000  0.993336  0.983911   {\"embedding_err\": 1.305739402770996}\n",
      "33  FedNCF_private2     0.963  0.963184   0.958416  0.968000  0.991788  0.992855  {\"embedding_err\": 1.0846112966537476}\n",
      "34      FedNCF_IMIA     0.540  0.540000   0.540000  0.540000       NaN       NaN                                     {}\n",
      "35           Random     0.480  0.648649   0.480000  1.000000  0.460661  0.458996                                     {}\n",
      "36    FedNCF_simple     0.990  0.989627   0.985537  0.993750  0.998317  0.998646                                     {}\n",
      "37   FedNCF_private     1.000  1.000000   1.000000  1.000000  1.000000  1.000000  {\"embedding_err\": 0.9523914456367493}\n",
      "38  FedNCF_private2     0.994  0.993776   0.989669  0.997917  0.998866  0.998286  {\"embedding_err\": 1.0912823677062988}\n",
      "39      FedNCF_IMIA     0.606  0.589583   0.589583  0.589583       NaN       NaN                                     {}\n",
      "40           Random     0.499  0.665777   0.499000  1.000000  0.506558  0.509153                                     {}\n",
      "41    FedNCF_simple     0.867  0.853685   0.946341  0.777555  0.952352  0.956216                                     {}\n",
      "42   FedNCF_private     0.964  0.963115   0.985325  0.941884  0.994972  0.994360  {\"embedding_err\": 0.9617342948913574}\n",
      "43  FedNCF_private2     0.975  0.974568   0.989669  0.959920  0.996912  0.997429  {\"embedding_err\": 0.9685680866241455}\n",
      "44      FedNCF_IMIA     0.560  0.559118   0.559118  0.559118       NaN       NaN                                     {}\n",
      "45           Random     0.501  0.667555   0.501000  1.000000  0.476482  0.480852                                     {}\n",
      "46    FedNCF_simple     0.987  0.987013   0.988000  0.986028  0.999228  0.999243                                     {}\n",
      "47   FedNCF_private     0.999  0.999001   1.000000  0.998004  1.000000  1.000000   {\"embedding_err\": 1.556351900100708}\n",
      "48  FedNCF_private2     1.000  1.000000   1.000000  1.000000  1.000000  1.000000    {\"embedding_err\": 1.83864426612854}\n",
      "49      FedNCF_IMIA     0.560  0.560878   0.560878  0.560878       NaN       NaN                                     {}\n"
     ]
    }
   ],
   "source": [
    "print(metrics.get_dataframe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: single query, single epoch\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_item_per_ranking = 10\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def simulate_attack(model, features, relevances, click_model):\n",
    "    params = model.gen_params()\n",
    "    ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "    features = features[ranking]\n",
    "    interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "    num_data = len(ranking)\n",
    "\n",
    "    # Remap the original ranking into the correct range\n",
    "    _, ranking = torch.where(\n",
    "        torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "    )\n",
    "\n",
    "    log_pos_bias_weight = model.calc_log_pos_bias_weight(\n",
    "        ranking, model.forward_multiple(params, features), num_data\n",
    "    )\n",
    "\n",
    "    target = model.grad(\n",
    "        params,\n",
    "        features,\n",
    "        ranking,\n",
    "        interactions,\n",
    "        log_pos_bias_weight=log_pos_bias_weight,\n",
    "    )\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: model.grad(\n",
    "            params,\n",
    "            features,\n",
    "            ranking,\n",
    "            I,\n",
    "            log_pos_bias_weight=log_pos_bias_weight,\n",
    "        ),\n",
    "        target,\n",
    "        num_data,\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "    return (interactions, preds, preds_raw)\n",
    "\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    for qid in tqdm(data.get_all_query_ids()):\n",
    "        relevances, features = data.get_data_for_queries([qid])[0]\n",
    "        features = torch.Tensor(features)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            for click_model_name, click_model in click_models.items():\n",
    "                interactions, preds, preds_raw = simulate_attack(\n",
    "                    model, features, relevances, click_model\n",
    "                )\n",
    "                metrics.update(\n",
    "                    f\"{model_name}_{click_model_name}\",\n",
    "                    interactions,\n",
    "                    preds,\n",
    "                    preds_raw=preds_raw,\n",
    "                )\n",
    "\n",
    "                # Random guess\n",
    "                random_preds_raw = torch.rand(preds_raw.shape)\n",
    "                random_preds = random_preds_raw.round()\n",
    "                metrics.update(\n",
    "                    f\"random_{click_model_name}\",\n",
    "                    interactions,\n",
    "                    random_preds,\n",
    "                    preds_raw=random_preds_raw,\n",
    "                )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: single query, multiple epochs\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_item_per_ranking = 10\n",
    "num_local_epochs = 5\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, features, ranking, interactions, num_local_epochs, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for _ in range(num_local_epochs):\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, features, relevances, click_model):\n",
    "    params = model.gen_params()\n",
    "    ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "    features = features[ranking]\n",
    "    interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "    num_data = len(ranking)\n",
    "\n",
    "    # Remap the original ranking into the correct range\n",
    "    _, ranking = torch.where(\n",
    "        torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "    )\n",
    "\n",
    "    target = train(model, params, features, ranking, interactions, num_local_epochs, local_lr)\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: train(model, params, features, ranking, I, num_local_epochs, local_lr),\n",
    "        target,\n",
    "        num_data,\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "    return (interactions, preds, preds_raw)\n",
    "\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    for qid in tqdm(data.get_all_query_ids()):\n",
    "        relevances, features = data.get_data_for_queries([qid])[0]\n",
    "        features = torch.Tensor(features)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            for click_model_name, click_model in click_models.items():\n",
    "                interactions, preds, preds_raw = simulate_attack(\n",
    "                    model, features, relevances, click_model\n",
    "                )\n",
    "                metrics.update(\n",
    "                    f\"{model_name}_{click_model_name}\",\n",
    "                    interactions,\n",
    "                    preds,\n",
    "                    preds_raw=preds_raw,\n",
    "                )\n",
    "\n",
    "                # Random guess\n",
    "                random_preds_raw = torch.rand(preds_raw.shape)\n",
    "                random_preds = random_preds_raw.round()\n",
    "                metrics.update(\n",
    "                    f\"random_{click_model_name}\",\n",
    "                    interactions,\n",
    "                    random_preds,\n",
    "                    preds_raw=random_preds_raw,\n",
    "                )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: multiple queries, no randomness\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [1, 8, 16, 24, 32]\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, grouped_data, click_model):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        features = torch.Tensor(features)\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    target = train(model, params, grouped_train_data, local_lr)\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: train(\n",
    "            model,\n",
    "            params,\n",
    "            [\n",
    "                (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "            ],\n",
    "            local_lr,\n",
    "        ),\n",
    "        target,\n",
    "        indices[-1][1],\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "    interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "    return (interactions, preds, preds_raw)\n",
    "\n",
    "\n",
    "for num_query in num_query_per_user:\n",
    "    print(f\"Num query: {num_query}\")\n",
    "    for _ in tqdm(range(num_sim_round)):\n",
    "        for qids in tqdm(\n",
    "            grouper(data.get_all_query_ids(), num_query, incomplete=\"ignore\"),\n",
    "            total=len(data.get_all_query_ids()) // num_query\n",
    "        ):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    interactions, preds, preds_raw = simulate_attack(\n",
    "                        model, grouped_data, click_model\n",
    "                    )\n",
    "                    metrics.update(\n",
    "                        f\"{model_name}_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        preds,\n",
    "                        preds_raw=preds_raw,\n",
    "                    )\n",
    "\n",
    "                    # Random guess\n",
    "                    random_preds_raw = torch.rand(preds_raw.shape)\n",
    "                    random_preds = random_preds_raw.round()\n",
    "                    metrics.update(\n",
    "                        f\"random_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        random_preds,\n",
    "                        preds_raw=random_preds_raw,\n",
    "                    )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: multiple queries, random order\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [8, 16, 24, 32]\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, grouped_data, click_model):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        features = torch.Tensor(features)\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    target = train(\n",
    "        model,\n",
    "        params,\n",
    "        random.sample(grouped_train_data, len(grouped_train_data)),\n",
    "        local_lr,\n",
    "    )\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: train(\n",
    "            model,\n",
    "            params,\n",
    "            [\n",
    "                (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "            ],\n",
    "            local_lr,\n",
    "        ),\n",
    "        target,\n",
    "        indices[-1][1],\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "    interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "    return (interactions, preds, preds_raw)\n",
    "\n",
    "\n",
    "for num_query in num_query_per_user:\n",
    "    print(f\"Num query: {num_query}\")\n",
    "    for _ in tqdm(range(num_sim_round)):\n",
    "        for qids in tqdm(\n",
    "            grouper(data.get_all_query_ids(), num_query, incomplete=\"ignore\"),\n",
    "            total=len(data.get_all_query_ids()) // num_query,\n",
    "        ):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    interactions, preds, preds_raw = simulate_attack(\n",
    "                        model, grouped_data, click_model\n",
    "                    )\n",
    "                    metrics.update(\n",
    "                        f\"{model_name}_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        preds,\n",
    "                        preds_raw=preds_raw,\n",
    "                    )\n",
    "\n",
    "                    # Random guess\n",
    "                    random_preds_raw = torch.rand(preds_raw.shape)\n",
    "                    random_preds = random_preds_raw.round()\n",
    "                    metrics.update(\n",
    "                        f\"random_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        random_preds,\n",
    "                        preds_raw=random_preds_raw,\n",
    "                    )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: random queries\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [8]\n",
    "num_train_query = 3\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1.0\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, grouped_data, click_model):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        features = torch.Tensor(features)\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    target_ind = random.sample(range(len(grouped_train_data)), num_train_query)\n",
    "\n",
    "    target = train(\n",
    "        model,\n",
    "        params,\n",
    "        [grouped_train_data[i] for i in target_ind],\n",
    "        local_lr,\n",
    "    )\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: train(\n",
    "            model,\n",
    "            params,\n",
    "            [\n",
    "                (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "            ],\n",
    "            local_lr,\n",
    "        ),\n",
    "        target,\n",
    "        indices[-1][1],\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "    interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "    return (interactions, preds, preds_raw, [indices[i] for i in target_ind])\n",
    "\n",
    "\n",
    "for num_query in num_query_per_user:\n",
    "    print(f\"Num query: {num_query}\")\n",
    "    for _ in tqdm(range(num_sim_round)):\n",
    "        for qids in tqdm(\n",
    "            grouper(data.get_all_query_ids(), num_query, incomplete=\"ignore\"),\n",
    "            total=len(data.get_all_query_ids()) // num_query,\n",
    "        ):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    interactions, preds, preds_raw, indices = simulate_attack(\n",
    "                        model, grouped_data, click_model\n",
    "                    )\n",
    "\n",
    "                    metrics.update(\n",
    "                        f\"{model_name}_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        preds,\n",
    "                        preds_raw=preds_raw,\n",
    "                    )\n",
    "\n",
    "                    actual_interactions = []\n",
    "                    actual_preds = []\n",
    "                    actual_preds_raw = []\n",
    "                    for (i1, i2) in indices:\n",
    "                        actual_interactions += interactions[i1:i2]\n",
    "                        actual_preds += preds[i1:i2]\n",
    "                        actual_preds_raw += preds_raw[i1:i2]\n",
    "                    \n",
    "                    metrics.update(\n",
    "                        f\"{model_name}_{click_model_name}_{num_query}_query_actual\",\n",
    "                        actual_interactions,\n",
    "                        actual_preds,\n",
    "                        preds_raw=actual_preds_raw,\n",
    "                    )\n",
    "\n",
    "                    # Random guess\n",
    "                    random_preds_raw = torch.rand(preds_raw.shape)\n",
    "                    random_preds = random_preds_raw.round()\n",
    "                    metrics.update(\n",
    "                        f\"random_{click_model_name}_{num_query}_query\",\n",
    "                        interactions,\n",
    "                        random_preds,\n",
    "                        preds_raw=random_preds_raw,\n",
    "                    )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDGD: multiple queries, random order, DP\n",
    "\n",
    "set_seed()\n",
    "\n",
    "num_query_per_user = [1, 4, 8, 12, 16]\n",
    "num_item_per_ranking = 10\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 1\n",
    "\n",
    "epsilons = [0.125, 0.25, 0.5, 1.0, 2.0, 4.0, 8.0, 16.0, 32.0, 64.0, 128.0]\n",
    "delta = 1e-08\n",
    "sensitivity = 4.0\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "def train(model, params, grouped_train_data, local_lr):\n",
    "    cur_params = params.clone()\n",
    "\n",
    "    for features, ranking, interactions in grouped_train_data:\n",
    "        cur_grad = model.grad(\n",
    "            cur_params,\n",
    "            features,\n",
    "            ranking,\n",
    "            interactions,\n",
    "        )\n",
    "\n",
    "        cur_params = cur_params + local_lr * cur_grad\n",
    "\n",
    "    return cur_params\n",
    "\n",
    "\n",
    "def simulate_attack(model, grouped_data, click_model, epsilon):\n",
    "    params = model.gen_params()\n",
    "\n",
    "    grouped_train_data = []\n",
    "    indices = []\n",
    "    start_ind = 0\n",
    "    for relevances, features in grouped_data:\n",
    "        features = torch.Tensor(features)\n",
    "        ranking = model.rank(params, features, sample=True)[:num_item_per_ranking]\n",
    "        features = features[ranking]\n",
    "        interactions = torch.Tensor(click_model.click(ranking, relevances))\n",
    "\n",
    "        # Remap the original ranking into the correct range\n",
    "        _, ranking = torch.where(\n",
    "            torch.sort(ranking)[0].unsqueeze(1) == ranking.unsqueeze(0)\n",
    "        )\n",
    "        grouped_train_data.append((features, ranking, interactions))\n",
    "        indices.append((start_ind, start_ind + len(ranking)))\n",
    "        start_ind += len(ranking)\n",
    "\n",
    "    target = train(\n",
    "        model,\n",
    "        params,\n",
    "        random.sample(grouped_train_data, len(grouped_train_data)),\n",
    "        local_lr,\n",
    "    )\n",
    "    target = (apply_gaussian_mechanism(target, epsilon, delta, sensitivity) - params) / local_lr\n",
    "\n",
    "    preds_raw, _ = reconstruct_interactions(\n",
    "        lambda I: (train(\n",
    "            model,\n",
    "            params,\n",
    "            [\n",
    "                (features, ranking, I[indices[idx][0] : indices[idx][1]])\n",
    "                for idx, (features, ranking, _) in enumerate(grouped_train_data)\n",
    "            ],\n",
    "            local_lr,\n",
    "        ) - params) / local_lr,\n",
    "        target,\n",
    "        indices[-1][1],\n",
    "        lr=atk_lr,\n",
    "        max_iter=max_iter,\n",
    "        num_rounds=num_atk,\n",
    "        return_raw=True,\n",
    "    )\n",
    "    preds = preds_raw.sigmoid().round().long()\n",
    "    interactions = torch.cat([I for (_, _, I) in grouped_train_data])\n",
    "    return (interactions, preds, preds_raw)\n",
    "\n",
    "\n",
    "for num_query in num_query_per_user:\n",
    "    print(f\"Num query: {num_query}\")\n",
    "    for _ in tqdm(range(num_sim_round)):\n",
    "        for qids in tqdm(\n",
    "            grouper(data.get_all_query_ids(), num_query, incomplete=\"ignore\"),\n",
    "            total=len(data.get_all_query_ids()) // num_query,\n",
    "        ):\n",
    "            grouped_data = data.get_data_for_queries(list(qids))\n",
    "\n",
    "            for model_name, model in models.items():\n",
    "                for click_model_name, click_model in click_models.items():\n",
    "                    for epsilon in epsilons:\n",
    "                        interactions, preds, preds_raw = simulate_attack(\n",
    "                            model, grouped_data, click_model, epsilon\n",
    "                        )\n",
    "                        metrics.update(\n",
    "                            f\"{model_name}_{click_model_name}_{num_query}_query_eps_{epsilon}\",\n",
    "                            interactions,\n",
    "                            preds,\n",
    "                            preds_raw=preds_raw,\n",
    "                        )\n",
    "\n",
    "                        # Random guess\n",
    "                        random_preds_raw = torch.rand(preds_raw.shape)\n",
    "                        random_preds = random_preds_raw.round()\n",
    "                        metrics.update(\n",
    "                            f\"random_{click_model_name}_{num_query}_query_eps_{epsilon}\",\n",
    "                            interactions,\n",
    "                            random_preds,\n",
    "                            preds_raw=random_preds_raw,\n",
    "                        )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe()\n",
    "dp[\"eps\"] = dp.index.to_series().apply(lambda name: float(name.split(\"_\")[name.split(\"_\").index(\"eps\") + 1]))\n",
    "dp[\"model\"] = dp.index.to_series().apply(lambda name: \"_\".join(name.split(\"_\")[:name.split(\"_\").index(\"eps\")]))\n",
    "dp = dp.reset_index()\n",
    "\n",
    "fig, ax = plt.subplots(ncols=2)\n",
    "\n",
    "for model in dp[(\"model\", \"\")].unique().tolist():\n",
    "    df = dp[dp[(\"model\", \"\")] == model].sort_values(by=[\"eps\"])\n",
    "    ax[0].plot(df[(\"eps\", \"\")].astype(str), df[(\"auc\", \"mean\")], 'o-', label=model)\n",
    "    ax[1].plot(df[(\"eps\", \"\")].astype(str), df[(\"auc-pr\", \"mean\")], 'o-', label=model)\n",
    "    ax[0].set_xticks(df[(\"eps\", \"\")].astype(str))\n",
    "    ax[1].set_xticks(df[(\"eps\", \"\")].astype(str))\n",
    "\n",
    "ax[0].set_ylabel(\"auc\")\n",
    "ax[1].set_ylabel(\"auc-pr\")\n",
    "\n",
    "ax[0].legend()\n",
    "fig.set_figwidth(10)\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epsilon in epsilons:\n",
    "    for num_query in num_query_per_user:\n",
    "        print(f\"Epsilon {epsilon}, num query {num_query}\")\n",
    "        for click_model in click_models.keys():\n",
    "            print(f\"{click_model} AUC p-value:\", ks_2samp(\n",
    "                metrics.df[metrics.df[\"name\"] == f\"linear_pdgd_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc\"],\n",
    "                metrics.df[metrics.df[\"name\"] == f\"random_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc\"],\n",
    "            ).pvalue)\n",
    "            print(f\"{click_model} AUC-PR p-value:\", ks_2samp(\n",
    "                metrics.df[metrics.df[\"name\"] == f\"linear_pdgd_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc-pr\"],\n",
    "                metrics.df[metrics.df[\"name\"] == f\"random_{click_model}_{num_query}_query_eps_{epsilon}\"].loc[:, \"auc-pr\"],\n",
    "            ).pvalue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collaborative Filtering\n",
    "\n",
    "set_seed()\n",
    "\n",
    "data = MovieLens(\"../dataset/ML-100K/u.data\")\n",
    "user_ids = data.get_all_user_ids()\n",
    "item_ids = data.get_all_item_ids()\n",
    "user_id_to_idx = {id: idx for idx, id in enumerate(user_ids)}\n",
    "item_id_to_idx = {id: idx for idx, id in enumerate(item_ids)}\n",
    "num_users = len(user_ids)\n",
    "num_items = len(item_ids)\n",
    "embedding_dim = 64\n",
    "neg_sample_ratio = 4\n",
    "\n",
    "local_lr = 1e-01\n",
    "\n",
    "num_sim_round = 1\n",
    "atk_lr = 1e-01\n",
    "max_iter = 1000\n",
    "num_atk = 5\n",
    "\n",
    "metrics = Metrics()\n",
    "\n",
    "for _ in tqdm(range(num_sim_round)):\n",
    "    user_embeddings = nn.Embedding(num_users, embedding_dim)\n",
    "    item_embeddings = nn.Embedding(num_items, embedding_dim)\n",
    "\n",
    "    fcf = CollaborativeFilteringRecommender()\n",
    "    fncf = NeuralCollaborativeFilteringRecommender(embedding_dim, [16, 8])\n",
    "\n",
    "    for user_id in tqdm(user_ids):\n",
    "        # Set up training data\n",
    "        interacted_items = data.get_item_ids_for_users([user_id])[0]\n",
    "        non_interacted_items = data.get_non_interacted_item_ids_for_users([user_id])[0]\n",
    "\n",
    "        num_pos = len(interacted_items)\n",
    "        sampled_non_interacted_items = random.sample(\n",
    "            non_interacted_items,\n",
    "            min(num_pos * neg_sample_ratio, len(non_interacted_items)),\n",
    "        )\n",
    "        num_neg = len(sampled_non_interacted_items)\n",
    "        num_data = num_pos + num_neg\n",
    "\n",
    "        user_embedding = (\n",
    "            user_embeddings(torch.LongTensor([user_id_to_idx[user_id]]))\n",
    "            .detach()\n",
    "            .view(-1)\n",
    "        )\n",
    "        item_embedding = item_embeddings(\n",
    "            torch.cat(\n",
    "                [\n",
    "                    torch.LongTensor([item_id_to_idx[id] for id in interacted_items]),\n",
    "                    torch.LongTensor(\n",
    "                        [item_id_to_idx[id] for id in sampled_non_interacted_items]\n",
    "                    ),\n",
    "                ]\n",
    "            )\n",
    "        ).detach()\n",
    "        interactions = torch.cat([torch.ones(num_pos), torch.zeros(num_neg)])\n",
    "        random_user_emb = torch.rand(embedding_dim)\n",
    "\n",
    "        # FCF Simple\n",
    "        target = fcf.item_grad(user_embedding, item_embedding, interactions)\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: fcf.item_grad(random_user_emb, item_embedding, I),\n",
    "            target,\n",
    "            num_data,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "        metrics.update(\n",
    "            f\"FCF_emb_{embedding_dim}_simple\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "        # FCF jointly estimate user embedding\n",
    "        preds_raw, user_embedding_est, _ = reconstruct_interactions(\n",
    "            lambda I, U: fcf.item_grad(U, item_embedding, I),\n",
    "            target,\n",
    "            num_data,\n",
    "            private_params_size=embedding_dim,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "        embedding_err = F.mse_loss(user_embedding_est, user_embedding).item()\n",
    "\n",
    "        metrics.update(\n",
    "            f\"FCF_emb_{embedding_dim}_joint\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "            extra_data={\"embedding_err\": embedding_err},\n",
    "        )\n",
    "\n",
    "        # FNCF setup\n",
    "        target = fncf.item_grad(user_embedding, item_embedding, interactions)\n",
    "        mean_norm = torch.linalg.vector_norm(target, dim=1).mean()\n",
    "        norm_scale = max(torch.Tensor([1.0]), torch.Tensor([1e+02]) / mean_norm)\n",
    "        custom_loss = lambda e1, e2: (e1 - e2).pow(2).sum(dim=1).sqrt().mean() * norm_scale\n",
    "\n",
    "        # FNCF simple\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: fncf.item_grad(random_user_emb, item_embedding, I),\n",
    "            target,\n",
    "            num_data,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            loss_func=custom_loss,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "        metrics.update(\n",
    "            f\"FNCF_emb_{embedding_dim}_simple\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "        # FNCF jointly estimate user embedding\n",
    "        preds_raw, user_embedding_est, _ = reconstruct_interactions(\n",
    "            lambda I, U: fncf.item_grad(U, item_embedding, I),\n",
    "            target,\n",
    "            num_data,\n",
    "            private_params_size=embedding_dim,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            loss_func=custom_loss,\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "        embedding_err = F.mse_loss(user_embedding_est, user_embedding).item()\n",
    "\n",
    "        metrics.update(\n",
    "            f\"FNCF_emb_{embedding_dim}_joint\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "            extra_data={\"embedding_err\": embedding_err},\n",
    "        )\n",
    "\n",
    "        # FNCF jointly estimate user embedding with neural net params\n",
    "        feature_grad = fncf.feature_grad(user_embedding, item_embedding, interactions)\n",
    "\n",
    "        preds_raw, user_embedding_est, _ = reconstruct_interactions(\n",
    "            lambda I, U: (\n",
    "                fncf.item_grad(U, item_embedding, I),\n",
    "                fncf.feature_grad(U, item_embedding, I, retain_graph=True),\n",
    "            ),\n",
    "            (target, feature_grad),\n",
    "            num_data,\n",
    "            private_params_size=embedding_dim,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            loss_func=lambda t1, t2: custom_loss(t1[0], t2[0]) + F.mse_loss(t1[1], t2[1]),\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "        embedding_err = F.mse_loss(user_embedding_est, user_embedding).item()\n",
    "\n",
    "        metrics.update(\n",
    "            f\"FNCF_emb_{embedding_dim}_joint_model\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "            extra_data={\"embedding_err\": embedding_err},\n",
    "        )\n",
    "\n",
    "        # FNCF simple with neural net params\n",
    "        feature_grad = fncf.feature_grad(user_embedding, item_embedding, interactions)\n",
    "\n",
    "        preds_raw, _ = reconstruct_interactions(\n",
    "            lambda I: (\n",
    "                fncf.item_grad(random_user_emb, item_embedding, I),\n",
    "                fncf.feature_grad(random_user_emb, item_embedding, I, retain_graph=True),\n",
    "            ),\n",
    "            (target, feature_grad),\n",
    "            num_data,\n",
    "            lr=atk_lr,\n",
    "            max_iter=max_iter,\n",
    "            num_rounds=num_atk,\n",
    "            loss_func=lambda t1, t2: custom_loss(t1[0], t2[0]) + F.mse_loss(t1[1], t2[1]),\n",
    "            return_raw=True,\n",
    "        )\n",
    "        preds = preds_raw.sigmoid().round().long()\n",
    "\n",
    "        metrics.update(\n",
    "            f\"FNCF_emb_{embedding_dim}_simple_model\",\n",
    "            interactions,\n",
    "            preds,\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "        # Random guess\n",
    "        preds_raw = 2 * torch.rand(num_data) - 1\n",
    "        metrics.update(\n",
    "            f\"Random_emb_{embedding_dim}\",\n",
    "            interactions,\n",
    "            preds_raw.sigmoid().round().long(),\n",
    "            preds_raw=preds_raw,\n",
    "        )\n",
    "\n",
    "        # IMIA FCF\n",
    "        # target = fcf.item_grad(user_embedding, item_embedding, interactions)\n",
    "        # preds = interaction_mia_fedrec(\n",
    "        #     lambda I: fcf.item_grad(random_user_emb, item_embedding, I),\n",
    "        #     target,\n",
    "        #     num_data,\n",
    "        #     select_ratio=interactions.mean(),\n",
    "        # )\n",
    "\n",
    "        # metrics.update(\n",
    "        #     \"FCF_IMIA\",\n",
    "        #     interactions,\n",
    "        #     preds,\n",
    "        # )\n",
    "\n",
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.df[[\"name\", \"auc\", \"auc-pr\"]].groupby(\"name\").describe().to_string())\n",
    "pairs = [(\"joint\", \"simple\"), (\"joint_model\", \"joint\"), (\"simple_model\", \"simple\"), (\"joint\", \"simple_model\")]\n",
    "for model1, model2 in pairs:\n",
    "    print(f\"FNCF {model1} vs FNCF {model2} AUC p-value:\", ks_2samp(\n",
    "        metrics.df[metrics.df[\"name\"] == f\"FNCF_emb_{embedding_dim}_{model1}\"].loc[:, \"auc\"],\n",
    "        metrics.df[metrics.df[\"name\"] == f\"FNCF_emb_{embedding_dim}_{model2}\"].loc[:, \"auc\"],\n",
    "        alternative=\"less\",\n",
    "    ).pvalue)\n",
    "    print(f\"FNCF {model1} vs FNCF {model2} AUC-PR p-value:\", ks_2samp(\n",
    "        metrics.df[metrics.df[\"name\"] == f\"FNCF_emb_{embedding_dim}_{model1}\"].loc[:, \"auc-pr\"],\n",
    "        metrics.df[metrics.df[\"name\"] == f\"FNCF_emb_{embedding_dim}_{model2}\"].loc[:, \"auc-pr\"],\n",
    "        alternative=\"less\",\n",
    "    ).pvalue)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ira",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
